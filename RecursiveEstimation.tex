% !TeX program = xelatex
% !TeX encoding = utf8
% !TeX root = RecursiveEstimation.tex
% vim:set ts=2 sw=2 et spell tw=78:

\documentclass[margin=tiny]{hsrzf}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Packages

%% The OST Student's package
\usepackage{oststud}

%% Mathematics
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{algpseudocode}

%% Lists
\usepackage{enumitem}

%% Language configuration
\usepackage{polyglossia}
\setdefaultlanguage{english}
\setotherlanguage[variant=swiss]{german}

%% License configuration
\usepackage[
  type={CC},
  modifier={by-nc-sa},
  version={4.0},
]{doclicense}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Metadata

\course{Electrical Engineering}
\module{Recursive Estimation}
\semester{Spring Semester 2023}

\authoremail{npross@student.ethz.ch}
\author{\textsl{Naoki Sean Pross} -- \texttt{\theauthoremail}}

% did someone help you with this work?
\contributors{
  % I created this template, does that count?
  Naoki Pross
  % do not forget to add yourself!
}

\title{Notes of \themodule}
\date{\thesemester}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Macros

% TODO: remove once oststud gets updated
\makeatletter
\newgeometry{
    hmargin=8mm,
    top=8mm,
    bottom=18mm,
    marginparsep=0pt,
    marginpar=0pt,
}
\renewcommand*{\Pr}[2][]{\ost@probability_{#1}\left\{#2\right\}}
\makeatother

\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{prop}{Proposition}[section]

\theoremstyle{definition}
\newtheorem{defn}{Definition}[section]
\newtheorem{alg}{Algorithm}[section]

\theoremstyle{remark}
\newtheorem*{example}{Example}
\newtheorem*{remark}{Remark}

\DeclareMathOperator{\rank}{rank}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Document

\begin{document}

% use roman numberals for introductiory pages
\pagenumbering{roman}

\maketitle

\begin{abstract}
  These are my notes of the course Recursive Estimation
  (\texttt{151-0566-00L}, spring semester 2023) by Dr. D'Andrea at ETH ZÃ¼rich.
  Almost all of the material in this comes from lecture notes, slides and
  exercises of the course, with exception of minor additions that were
  introduced for clarity.
\end{abstract}

% show the names of the people who contributed to this document.
% \section*{Contributors}
% \thecontributors

\section*{License}
\doclicenseThis

\tableofcontents

% actual content
\clearpage
\setcounter{page}{1}
\pagenumbering{arabic}

\twocolumn

\section{Probability Basics Review}

\subsection{Random Variables}

\begin{defn}[Random Variable]
  We call $x \in \mathcal{X}$ a random variable (RV) from the set of possible
  outcomes $\mathcal{X}$, with an associated probability density function
  (PDF) $p_x : \mathcal{X} \to \mathbb{R}$ that satisfies
  \begin{itemize}
    \item $p_x(\bar{x}) \geq 0$ for all $\bar{x} \in \mathcal{X}$, and
    \item if $\mathcal{X}$is countable (discrete random variable, DRV)
      \[
        \sum_{\bar{x} \in \mathcal{X}} p_x(\bar{x}) = 1
        \quad\text{or}\quad
        \int_\mathcal{X} p_x(\bar{x}) d\bar{x} =1,
      \]
      in the case of a continuous random variable (CRV) ($\mathcal{X}$ is an
      interval).
  \end{itemize}
\end{defn}

The PDF is then used to define the notion of probability, i.e. the probability
that a discrete RV $x$ takes the value $\bar{x} \in \mathcal{X}$ is
$p_x(\bar{x})$, and is written as $\Pr{x = \bar{x}}$.

For a continuous RV $x$ the probability of any specific value is always 0,
instead we can only can only refer to the RV being in some interval $[a,b]
\subseteq \mathcal{X}$ and we write $\Pr{x \in [a,b]} = \int_a^b p_x(\bar{x})
\,d\bar{x}$.

\begin{defn}[Joint PDF]
  Let $x \in \mathcal{X}$ and $y \in \mathcal{Y}$ be RVs. The joint PDF
  satisfies
  \begin{itemize}
    \item $p_{xy}(\bar{x}, \bar{y}) \geq 0$ for all $x \in\mathcal{X}$ and $y
      \in \mathcal{Y}$,
    \item further
      \[
        \sum_{\bar{x}\in\mathcal{X}}\sum_{\bar{y}\in\mathcal{Y}}
        p_{xy}(\bar{x}, \bar{y}) = 1
        \text{ or }
        \iint\limits_{\mathcal{X}\times\mathcal{Y}} p_{xy}(\bar{x}, \bar{y})
        \,d\bar{x}d\bar{y} = 1
      \]
      for DRVs or CRVs, respectively.
  \end{itemize}
\end{defn}

The interpretation of the joint PDF is that both $x$ equals $\bar{x}$ and $y$
equals $\bar{y}$.

\begin{defn}[Marginalization]
  From a joint PDF of $x$ and $y$ we can redefine the PDF of either variable
  by going through each case of the other:
  \[
    p_x(\bar{x}) = \sum_{\bar{y} \in \mathcal{Y}} p_{xy} (\bar{x}, \bar{y})
    \text{~~or~~}
    p_x(\bar{x}) = \int_\mathcal{Y} p_{xy} (\bar{x}, \bar{y}) \,
    d\bar{y}
  \]
  and similar for $p_y(\bar{y})$.
\end{defn}

\begin{defn}[Conditioning]
  Given the RVs $x$, $y$ and $p_{xy}(\bar{x}, \bar{y})$ define
  \[
    p_{x|y}(\bar{x} | \bar{y}) = \frac{p_{xy}(\bar{x}, \bar{y})}{p_y(\bar{y})}
    \iff
    p_{x|y}(\bar{x} | \bar{y}) p_y(\bar{y}) = p_{xy}(\bar{x}, \bar{y})
  \]
  when $p_y(\bar{y}) \neq 0$.
\end{defn}

The $p_{x|y}(\bar{x} | \bar{y})$ is reads $x$ given $y$ ans is to be
understood the probability of $x$ while keeping $y$ fixed.

The above can generalized for more variables by having a vector of RVs
$(x_1,\ldots, x_N) \in \mathcal{X}^N$. In particular $p : \mathcal{X}^N \to
\mathbb{R}$ is still a scalar. Marginalization still applies
\[
  p(x_1, x_3, \ldots, x_{N-1}) = \sum_{(x_{2}, x_{N}) \in \mathcal{X}^2}
  p(x_1, x_2, \ldots, x_N),
\]
and so does conditioning
\[
  p(x_1, \ldots | x_N) p(x_N) = p(x_1, \ldots x_N).
\]
However, now there can be mixed cases of conditioning.
\begin{prop}[Conditioning]
  Given the RVs $x, y, z$:
  \[
    p_{x|yz}(\bar{x} | \bar{y}, \bar{z}) = 
      \frac{p_{xy|z}(\bar{x},\bar{y} | \bar{z})}{p_{y|x}(\bar{y} | \bar{z})}.
  \]
  This generalizes to more variables.
\end{prop}

For RVs there is a notion if independence, that is, they do not affect each
other.

\begin{defn}[Independence]
  The RVs $x$ and $y$ are said to be independent if $p(x|y) = p(x)$.
\end{defn}

From the definition it follows that $p(x,y) = p(x)p(y)$ and $p(y|x) = p(y)$.

\subsection{Expectation and Moments}

The expectation is to be understood as a statistical average, or as a weighted
sum with the coefficients being the probability.

\begin{defn}[Expectation]
  For a RV $x \in \mathcal{X}$
  \[
    \E[x]{x}
       = \sum_{\bar{x} \in \mathcal{X}} \bar{x} p_x(\bar{x})
       \text{ or }
       \int_\mathcal{X} \bar{x} p_x(\bar{x}) \, d\bar{x}.
  \]
\end{defn}

In the definition above $p_x$ can be replaced with a conditional $p_{x|y}$, to
obtain the conditional expectation
\[
  \E[x|y]{x | \bar{y}} 
    = \int_\mathcal{X} \bar{x} p_{x|y}(\bar{x} | \bar{y}) \, d\bar{x}.
\]

\begin{thm}[Law of the Unconscious Statistician]
  Let $y = g(x) \in \mathcal{Y} = g(\mathcal{X})$ where $x \in \mathcal{X}$ is
  a DRV or CRV. Then
  \[
    \E[y]{y} = \sum_{\bar{x} \in \mathcal{X}} g(\bar{x}) p_x(\bar{x})
      \text{ or }
      \int_\mathcal{X} g(\bar{x}) p_x(\bar{x}) \, d\bar{x},
  \]
  or more compactly $\E[y]{y} = \E[x]{g(x)}$.
\end{thm}

\begin{defn}[Variance]
  For a RV $x \in \mathcal{X}$
  \[
    \Var[x]{x} = \E[x]{(x - \E[x]{x})\mt{(x - \E[x]{x})}}.
  \]
  If $x$ is a vector the resulting matrix is sometimes called covariance.
\end{defn}

\subsection{Sampling Distributions} 
\label{sec:probability-review:sampling-distributions}

Most mathematical libraries offer a function to sample a RV that is uniformly
distributed on $(0,1)$ (in MATLAB \texttt{rand()}). In other words we have a
PDF
\[
  p_u(\bar{u}) = \begin{cases}
    1 & \bar{u} \in (0,1) \\
    0 & \text{otherwise}
  \end{cases}.
\]
We can use $p_u$ to generate samples for any other desired PDF using the
following algorithms.

\begin{alg}[Sample a DRV] \label{alg:sample-drv}
  Given a derided PDF $\hat{p}_x$ for a DRV $x \in \mathcal{X} = \mathbb{Z}$,
  its cumulative distribution function (CDF) is a nondecreasing function
  \[
    \hat{F}_x (\bar{x}) = \sum_{i = -\infty}^{\bar{x}} \hat{p}_x (i),
    = \Pr{x \leq \bar{x}}
  \]
  and has the property that $\hat{F}_x(-\infty) = 0$ and $\hat{F}_x(\infty) =
  1$.

  Let $\bar{u}$ be the samples of $u \sim \mathcal{U}(0,1)$. To find
  a sample $\bar{x}$ of $x$ we solve for a $\bar{x}$ such that
  $\hat{F}_x(\bar{x} -1) < \bar{u}$ and $\bar{u} \leq \hat{F}_x(\bar{x})$.
\end{alg}

\begin{alg}[Sample multiple finite DRV]
  Given a desired joint PDF $\hat{p}_{xy}$ for the scalar DRVs $x \in
  \mathcal{X}$ and $y \in \mathcal{Y}$, where $N_x = |\mathcal{X}|$ and
  $N_y = |\mathcal{Y}|$ are both finite, let $\mathcal{Z} = \{1,2,\ldots,
  N_xN_y\}$. Then define a new $\hat{p}_z$ such that $\hat{p}_z(1) =
  \hat{p}_{xy}(1,1)$, $\hat{p}_z(2) = \hat{p}_{xy}(1,2)$, \dots,
  $\hat{p}_z(N_xN_y) = \hat{p}_{xy}(N_x, N_y)$, and apply algorithm
  \ref{alg:sample-drv} to $\hat{p}_z$.
\end{alg}

If the constraint of having finite sets of outcome is a problem, the following
algorithm also works for infinite sets $\mathcal{X}$ and $\mathcal{Y}$.

\begin{alg}[Sample multiple DRVs] \label{alg:sample-multiple-drvs}
  Given a desired joint PDF $\hat{p}_{xy}$, decompose it into
  $\hat{p}_{x|y}(\bar{x}|\bar{y}) \hat{p}_y(\bar{y})$. Apply algorithm
  \ref{alg:sample-drv} to get a sample $\bar{y}$ for $y$ via
  $\hat{p}_y(\bar{y})$, then with $\bar{y}$ fixed apply algorithm
  \ref{alg:sample-drv} again to get $\bar{x}$ for $x$ via
  $\hat{p}_{x|y}(\bar{x}|\bar{y})$.
\end{alg}

\begin{remark}
  The independence of the uniform number generator between successive calls is
  important. Further, both algorithms were described for 2 variables but they
  both generalize any number of DRVs.
\end{remark}

\begin{alg}[Sample a CRV] \label{alg:sample-crv}
  Given a desired piecewise continuous and bounded PDF $\hat{p}_x$ for a CRV
  $x$, let
  \[
    \hat{F}_x(\bar{x})
      = \int_{-\infty}^{\bar{x}} \hat{p}_x(\lambda) \, d\lambda
      = \Pr{x \leq \bar{x}}
  \]
  be the CDF of $x$. To find a sample of $x$ let $\bar{x}$ be any solution to
  $\bar{u} = \hat{F}_x(\bar{x})$, then $x$ has PDF $p_x = \hat{p}_x$.
\end{alg}

\begin{alg}[Sample multiple CRVs]
  Analogously to algorithm \ref{alg:sample-multiple-drvs} decompose the
  given desired joint PDF into $\hat{p}_{xy}(\bar{x},\bar{y}) =
  \hat{p}_{x|y}(\bar{x}|\bar{y}) \hat{p}_y(\bar{y})$. Then, apply algorithm
  \ref{alg:sample-crv} to get a $\bar{y}$ for $y$ via $\hat{p}_y(\bar{y})$,
  and with $\bar{y}$ fixed apply it again to get a sample $\bar{x}$ of $x$
  with $\hat{p}_{x|y}(\bar{x}|\bar{y})$.
\end{alg}

\subsection{Change of Variables}

When we work with functions of RVs we usually also wish to know the
PDFs of the results.

\begin{prop}[Change of variables for DRVs]
  Let $p_y$ be given for $y \in \mathcal{Y}$ and consider $x = g(y) \in
  \mathcal{X} = g(\mathcal{Y})$. For each $\bar{x} \in \mathcal{X}$ let
  \[
    \mathcal{Y}_{\bar{x}} = \{ \bar{y}_i : \bar{y}_i \in \mathcal{Y},
    g(\bar{y}_i) = \bar{x} \},
  \]
  then
  \[
    p_x(\bar{x}) = 
      \sum_{\bar{y} \in \mathcal{Y}_{\bar{x}}} p_y(\bar{y}) =
      \sum_{\bar{y} \in \mathcal{Y} : g(\bar{y}) = \bar{x}}
        p_y(\bar{y}).
  \]
\end{prop}

\begin{prop}[Change of variables for CRVs]
  Consider a strictly monotonic differentiable continuous function $x = g(y)$,
  then
  \[
    p_x(\bar{x}) = \frac{p_y(\bar{y})}{g'(\bar{y})}
      = \frac{p_y \circ g^{-1}(\bar{x})}{g' \circ g^{-1} (\bar{x})}.
  \]
\end{prop}

\begin{prop}[Multivariate change of variables for CRVs]
  \label{pro:multivariate-change-var}
  Let $g : \mathbb{R}^m \to \mathbb{R}^m, w \mapsto g(w)$, be a map with
  nonsingular Jacobian for all $w$, i.e.
  \[
    \det \frac{\partial g}{\partial w} = \det \begin{bmatrix}
      \partial_{w_1} g_1 & \cdots & \partial_{w_m} g_1 \\
      \vdots & \ddots & \vdots \\
      \partial_{w_1} g_m & \cdots & \partial_{w_m} g_m
    \end{bmatrix}
    \neq 0, \quad \forall w.
  \]
  Further, assume that $z = g(w)$ has a unique solution for $w$ in terms of
  $z$, say $w = h(z)$. Then
  \[
    p_z(\bar{z}) = p_w(h(\bar{z})) \left|
      \det \frac{\partial g}{\partial w}(h(\bar{z})) \right|^{-1}.
  \]
\end{prop}

\subsection{Bayes' Theorem}

\begin{thm}[Bayes' theorem] For the RVs $x$ and $z$
\[
  p(x|z) = p(z|x)\frac{p(x)}{p(z)}.
\]
\end{thm}

\begin{remark}
  The interpretation is as follows: $x$ is the unknown quantity of interest
  (state); $p(x)$ is the prior belief of the state; $z$ is an observation
  related to the state; $p(z|x)$ is, for a given state, what is the
  probability of observing $z$? $p(x|z)$ is the posterior belief, that is the
  observation what is the probability that the state is $x$?
\end{remark}

Bayes' theorem is a systematic way of combining prior beliefs with
observations. Since observing $z$ is usually not enough to directly determine
$x$. That is because usually $\dim z < \dim x$ and with noise $p(z|x)$ that is not
``sharp''.

\begin{prop}[Generalization of Bayes' theorem]
  Suppose there are $N$ (vector or scalar) observations $z_1, \ldots, z_N$.
  Assuming conditional independence, i.e.
  \[
    p(z_1, \ldots, z_N|x) = p(z_1|x) \cdots p(z_N|x),
  \]
  then
  \[
    p(x|z_1, \ldots, z_N) 
      = \frac{p(x) \prod_i p(z_i | x)}{p(z_1, \ldots, z_N)},
  \]
  where the normalization
  \[
    p(z_1, \ldots, z_N) = \sum_{x \in \mathcal{X}} p(x) \prod_i p(z_i | x)
  \]
  by the total probability theorem.
\end{prop}
A possible interpretation for the independence assumption is that a
measurement of the state $x$ is corrupted by noise which is independent at
each time step.

\subsection{Gaussian Random Variables}

For Kalman filter we need to know the properties of Gaussian RVs.

\begin{defn}[Gaussian RV (GRV)]
  The PDF of a Gaussian (normally) distributed $D$-dimensional CRV $y = (y_1,
  \ldots, y_D)$ is
  \[
    p(y) = \frac{1}{\sqrt{(2\pi)^D \det \Sigma}} \exp \left( 
        -\frac{1}{2} \mt{(y - \mu)} \minv{\Sigma} (y - \mu)
      \right),
  \]
  where $\mu \in \mathbb{R}^D$ is the mean vector and $\Sigma \in
  \mathbb{R}^{D\times D}$ and $\Sigma \succ 0$ (is a 
  positive definite matrix) and symmetric ($\mt{\Sigma} = \Sigma$).
\end{defn}

\begin{prop}
  In the special case where $\Sigma$ is a diagonal matrix with entries
  $\sigma^2_i$
  \[
    p(y) = \prod_{i=1}^D \frac{1}{\sqrt{2\pi \sigma^2_i}}
      \exp\left(-\frac{(y_i - \mu_i)^2}{2\sigma^2_i}\right).
  \]
  Hence, the PDF is a product of scalar GRVs, and thus the variables are
  mutually independent (the converse is also true).
\end{prop}

\begin{remark}
  For a time-dependent GRV $y(k)$ we say that it is \emph{spatially}
  independent for a fixed time $k$ if $y_1(k)$, \dots, $y_D(k)$ are
  mutually independent, and \emph{temporally} independent if $y(1)$, \dots,
  $y(k)$ are mutually independent.
\end{remark}

\begin{defn}[Jointly GRVs]
  Two GRVs $x$ and $y$ are said to be jointly Gaussian if the vector RV $(x,
  y)$ is also a GRV.
\end{defn}

\begin{remark}
  If two variables are GRVs this does not imply that they are jointly GRVs.
\end{remark}

\begin{prop} \label{lem:independent-grvs-joint}
  If two GRVs $x \sim \mathcal{N}(\mu_x, \Sigma_x)$ and $y \sim
  \mathcal{N}(\mu_y, \Sigma_y)$ are independent, i.e. $p(x,y) = p(x)p(y)$
  then they are jointly Gaussian.
\end{prop}
\begin{proof}
  We assume hat $p(x, y) = p(x)p(y)$. By computing $p(x)p(y)$ we see that it
  is still Gaussian
  \begin{align*}
    &p(x)p(y)
    \propto \exp \Big(
      -\frac{1}{2} \Big[
        \mt{(x - \mu_x)} \minv{\Sigma}_x (x - \mu_x) \\
        &\qquad\qquad\qquad\qquad
          + \mt{(y - \mu_y)} \minv{\Sigma}_y (x - \mu_y)
      \Big]
    \Big) \\
    &= \exp \Bigg(
      -\frac{1}{2} \mt{\begin{bmatrix}
        x - \mu_x \\
        y - \mu_y 
      \end{bmatrix}}
      \begin{bmatrix}
        \minv{\Sigma}_x & 0 \\
        0 & \minv{\Sigma}_y
      \end{bmatrix}
      \begin{bmatrix}
        x - \mu_x \\
        x - \mu_y
      \end{bmatrix}
    \Bigg).
    \qedhere
  \end{align*}
\end{proof}

\begin{lemma}[Affine transformation of a GRV is a GRV]
  \label{lem:affine-grv}
  Let $y$ be a GRV, $M$ a matrix and $b$ a vector of appropriate size, then $x
  = My + b$ is a GRV.
\end{lemma}

\begin{lemma}[Linear combination of jointly GRVs is a GRV]
  Let $x$ and $y$ be jointly Gaussian GRVs, then $z = M_x x + M_y y$ where
  $M_x$ and $M_y$ are constant matrices of appropriate dimensions, is a GRV.

\end{lemma}

\section{Bayesian Tracking} \label{sec:bayesian-tracking}

\subsection{Problem Statement}

Let $x(k) \in \mathcal{X}$ be a vector valued state at time $k \in
\mathbb{Z}^+$ we wish to estimate. Assume $x$ is a DRV and $\mathcal{X}$ is
finite. Let $z(k)$ be a vector valued measurement which can be a DRV or CRV.

The model for the dynamics of the system and measurements may be nonlinear and
time-varying:
\begin{align*}
  x(k) &= q_{k-1}(x(k-1), v(k-1)), & k&=1,2,\ldots \\
  z(k) &= h_k(x(k), w(k)),
\end{align*}
where $x(0), \{v(\cdot)\},$ and $\{w(\cdot)\}$ are mutually independent with
known PDFs. Any known input to the system is not explicitly included as it can
be embedded into $q_{k-1}$ and $h_k$.

Let $z(1:k)$ denote the set $\{z(1), \ldots, z(k)\}$. The goal is to
\emph{efficiently} compute $p(x(k) | z(1:k))$, that is, the full conditional
probability density function of the state.

\subsection{Recursive Estimator}
\label{sec:bayesian-tracking:recursive-estimator}

Bayesian tracking is a two step recursive algorithm:
\begin{itemize}
  \item \textbf{Prior update}: the state estimate is predicted forward using
    the process model.
  \item \textbf{Measurement update}: the prior is combined with observations /
    measurements.
\end{itemize}

\begin{prop}[Prior Update]
  We can predict the PDF of $x(k)$ based on past measurements $z(1:k-1)$ using
  \begin{gather*}
    p(x(k)|z(1:k-1)) = \\
      \sum_{x(k-1) \in \mathcal{X}}
      \underbrace{p(x(k) | x(k-1))}_{\text{process model}} ~
      \underbrace{p(x(k-1) | z(1:k-1))}_{\text{previous iteration}},
  \end{gather*}
  where $p(x(k) | x(k-1))$ can be computed from $p(v(k-1))$ and
  $q_{k-1}(\cdot, \cdot)$ using changes of variables.
\end{prop}

\begin{remark}
  The change of variables required in the prior update may not be
  straightforward.
\end{remark}

\begin{prop}[Measurement Update]
  \label{pro:measurement-update}
  We combine the new observation using Bayes' rule and get
  \begin{align*}
    p(x(k) &| z(1:k)) = p(x(k) | z(k), z(1:k-1)) = \\
      &\frac{
        \overbrace{p(z(k) | x(k), z(1:k-1))}^{\text{measurement model}}
        \overbrace{p(x(k) | z(1:k-1))}^{\text{prior}}
      }{\underbrace{p(z(k) | z(1:k-1))}_\text{normalization}}
  \end{align*}
  where the normalization can be computed using the total probability theorem
  \begin{align*}
    p(z(k) &| z(1:k-1)) =  \\
      &\sum_{x(k) \in \mathcal{X}} p(z(k) | x(k)) p(x(k) | z(1: k-1)).
  \end{align*}
\end{prop}

To implement this on a computer, there is the following algorithm.

\begin{alg}[Recursive Estimator]
  Enumerate the state space $\mathcal{X} = \{0,1, \ldots, N-1\}$. Define:
  \begin{itemize}
    \item $\vec{a}^i_{k|k} = p_{x(k) | z(1:k)}(i | \bar{z}(1:k))$ with
      $i=0,1$, \dots, $N-1$, an array with $N$ elements used to store the
      posterior PDF at time $k$. 
    \item $\vec{a}^i_{k|k-1} = p_{x(k) | z(1:k-1)}(i | \bar{z}(1:k-1))$,
      $i=0$, \dots, $N-1$ to store the prior PDF at time $k$.
  \end{itemize}
  Then, compute an expression for
  \begin{itemize}
    \item $p_{x(k)|x(k-1)}(i|j)$ using the process model $x(k) =
      q_{k-1}(x(k-1), v(k-1))$ and $p_{v(k-1)}(\bar{v}(k-1))$.
    \item $p_{z(k)|x(k)}(\bar{z}(k)|i)$ using the observation model $z(k) =
      h_k(x(k),w(k))$ and $p_{w(k)}(\bar{w}(k))$.
  \end{itemize}
  \algrenewcomment[1]{\(\triangleright\) {\itshape #1}}
  \begin{algorithmic}
    \Procedure{Estimator}{$p_{x(0)}(0), \ldots, p_{x(0)}(N-1)$}
      \State\Comment{Initialization}
      \State \(\vec{a}^i_{0|0} \gets p_{x(0)}(i), \quad 
          \forall i \in \{0,\ldots,N-1\}
        \)
      \Loop
        \ForAll {$i \in \{0,\ldots,N-1\}$}
          \State\Comment{Prior update}
          \State \(
              \displaystyle \vec{a}^i_{k|k-1} \gets 
              \sum_{j=0}^{N-1} p_{x(k)|x(k-1)}(i | j) ~ \vec{a}^j_{k-1|k-1}
            \)
          \State\Comment{Measurement update}
          \State \(
              \displaystyle \vec{a}^i_{k|k} \gets 
              \frac{p_{z(k)|x(k)}(\bar{z}(k)|i) ~ \vec{a}^j_{k|k-1}}
              {\displaystyle \sum_{j=0}^{N-1} 
                p_{z(k)|x(k)}(\bar{z}(k)|j) ~ \vec{a}^j_{k|k-1}}
            \)
        \EndFor
      \EndLoop
    \EndProcedure
  \end{algorithmic}
\end{alg}

%% TODO: Add example problem?
%% TODO: remarks on choice of parameters / possible errors

\section{Extracting Estimates}

The conditional PDF $p_{x|z}(\bar{x}|\bar{z})$ for the quantity $x$ and its
observations $z$ captures the full information that one has about $x$ in the
Bayesian sense. However, we may be interest in just on an estimate $\hat{x}$
of $x$.

\subsection{Maximum Likelihood (ML)}

ML applies when $x \in \mathcal{X}$ is an unknown (constant) parameter without
a (known) probabilistic description $p_x(\bar{x})$.

\begin{defn}[Maximum Likelihood Estimator]
  Let $z \in \mathcal{Z}$ be the measurement of the observation model
  $p_{z|x}(\bar{z} | \bar{x})$. For a given observation $\bar{z}$ ML seeks the
  value for the parameter $x$ that makes the observation $\bar{z}$ most
  likely:
  \[
    \hat{x}^\text{ML} = \argmax_{\bar{x} \in \mathcal{X}}
      p_{z|x} (\bar{z} | \bar{x}).
  \]
  In this context $p_{z|x} (\bar{z} | \bar{x})$ is called \emph{likelihood
  function}.
\end{defn}

\begin{example}[Least Squares]
  Suppose there is an observation model, whereby we have $m$ measurements of
  $n$ states:
  \[
    \begin{bmatrix} z_1 \\ \vdots \\ z_m \end{bmatrix}
    = \begin{bmatrix}
        h_{11} & \cdots & h_{1n} \\
        \vdots & \ddots & \vdots \\
        h_{m1} & \cdots & h_{mn}
    \end{bmatrix}
    \begin{bmatrix} x_1 \\ \vdots \\ x_n \end{bmatrix}
    + \begin{bmatrix} w_1 \\ \vdots \\ w_m \end{bmatrix}.
  \]
  Or, more compactly $z = Hx + w$, with $z,w \in \mathbb{R}^m$, $x \in
  \mathbb{R}^n$, $H \in \mathbb{R}^{m\times n}$, $m > n$ and $w_i \sim
  \mathcal{N}(0,1)$. Further, we assume that the $w_i$ are mutually
  independent and that $H$ has full column rank ($Hx = 0$ implies $x=0$).

  We apply the multivariate change of variables of proposition
  \ref{pro:multivariate-change-var}, so in this case, $z = g_x(w)$ and the
  unique solution is $w = h_x(z) = z - Hx$. Here, the Jacobian is
  nonsingular since
  \[
    \det \frac{\partial g_x}{\partial w} = 
    \det \partial_w \left(Hx + w\right) = 1.
  \]
  Hence
  \[
    p_{z|x}(\bar{z} | \bar{x})
      = p_w(\bar{z} - H\bar{x})
      = \prod_{i=1}^m p_w(\bar{z}_i - H_i\bar{x}),
  \]
  where in the first equality the conditioning of $x$ can be dropped because
  $w$ and $x$ are assumed to be independent, then the second equality is
  justified by the mutual independence of the $w_i$'s, and we use $H_i$ to
  denote the $i$-th row of $H$ (measurement).
  Now, because $p_w$ is Gaussian
  \[
      \prod_{i=1}^m p_w(\bar{z}_i - H_i\bar{x})
      \propto \exp \left(
        -\frac{1}{2} \sum_{i=1}^m (\bar{z}_i - H_i \bar{x})^2
      \right).
  \]
  To apply ML we need to maximixe the sum in the exponent. Differentiating it
  and setting it to zero yields
  \[
    \mt{H}(\bar{z} - H\bar{x}) = 0 \implies
      \bar{x} = \minv{(\mt{H} H)} \mt{H} \bar{z},
  \]
  that is, the least squares solution.
\end{example}

%% TODO: examples from problem set 3

\subsection{Maximum a Posteriori (MAP)}

The maximum a posteriori estimate applies when $x$ is a RV with known PDF.

\begin{defn}[Maximum a Posteriori Estimator]
  Let $z$ be the measurement of tbe observation model $p_{z|x}(\bar{z} |
  \bar{x})$. For a given obserservation $\bar{z}$ MAP looks for the most
  likely choice of $\bar{x}$ given the previous belief about $x$:
  \[
    \hat{x}^\text{MAP} = \argmax_{\bar{x} \in \mathcal{X}}
      p_{z|x}(\bar{z} | \bar{x}) p_x(\bar{x}).
  \]
\end{defn}

\begin{remark}
  If $p_x$ is constant (uniform), then $\hat{x}^\text{MAP} =
  \hat{x}^\text{ML}$, i.e. the prior does not provide any additional
  information.
\end{remark}

\begin{example}
  Consider the scalar observation model $z = x + w$ with $w \sim
  \mathcal{N}(0,1)$, $x \sim \mathcal{N}(\mu, \sigma^2)$, $w$ and $x$
  independent. Then
  \begin{gather*}
    p_x(\bar{x}) \propto \exp\left(
      -\frac{1}{2} \frac{(\bar{x} - \mu)^2}{\sigma^2}
    \right),
    \text{ and } \\
    p_{z|x}(\bar{z}|\bar{x}) \propto \exp\left(
      -\frac{1}{2} (\bar{z} - \bar{x})^2
    \right).
  \end{gather*}
  To apply MAP compute $p_{x|z} (\bar{x} | \bar{z})$, differentiate w.r.t.
  $\bar{x}$ and set to zero. The result is
  \[
    \bar{x} = \frac{1}{1 + \sigma^2} \mu + \frac{\sigma^2}{1 + \sigma^2}
    \bar{z},
  \]
  a weighted sum. Notice that when $\sigma \to \infty$ ($x$ is uniformly
  distributed), $\bar{x} = \bar{z}$ is the ML.
\end{example}

\subsection{Recursive Least Squares (RLS)}

\subsubsection{Problem Statement}

We consider the observation model for a constant $x$
\[
  z(k) = H(k) x + w(k),
  \quad
  z(k), w(k) \in\mathbb{R}^m, x \in\mathbb{R}^n.
\]
The given prior knowledge are the mean $\hat{x}_0 = \E{x}$ and variance $P_x =
\Var{x}$ of $x$. Further, we assume that the noise $w(k)$ is zero-mean
$\E{w(k)} = 0$, with known variance $R(k) = \Var{w(k))}$ and mutually
independent in time $k$ and also with $x$. Typically it is also the case that
we have more equations than observations, i.e. $n > m$, and information is
obtained ``over time''.

The goal is to compute an estimate $\hat{x}(k)$ of $x$ from the observations
$\{\bar{z}(1), \bar{z}(2), \ldots, \bar{z}(k)\}$ in the least square sense,
that is, minimizing a quadratic error.

\subsubsection{Standard Weighted LS}

%% TODO: Add with prior from problem set 3 p 9, and give more context from p3
A naive strategy is to wait until one has collected enough samples to perform
a weighted LS. Neglecting the prior, if we have data until time $k$:
\[
  \begin{bmatrix} z(1) \\ \vdots \\ z(k) \end{bmatrix} =
  \begin{bmatrix} H(1) \\ \vdots \\ H(k) \end{bmatrix} x +
  \begin{bmatrix} w(1) \\ \vdots \\ w(k) \end{bmatrix},
\]
or $\vec{z} = \mx{H} x + \vec{w}$, then $\mx{R} =
\operatorname{blockdiag}(R(1), \ldots, R(k))$
\begin{align*}
  \hat{x}^\text{WLS}(k) &= \argmin_{\hat{x}} \{
    (\mt{\bar{\vec{z}} - \mx{H} \hat{x})} \minv{\mx{R}}
      (\bar{\vec{z}} - \mx{H} \hat{\vec{x}})
  \} \\
  &= \minv{(\mt{\mx{H}} \minv{\mx{R}} \mx{H})}
    \mt{\mx{H}} \minv{\mx{R}} \bar{\vec{z}}
\end{align*}

The obvious problem with this approach is that as time progresses ($k$
increases) the LS problem grows in dimension, until it becomes computationally
intractable.

\subsubsection{Recursive LS}

A more effective solution is a recursive algorithm. This is a precursor to the
Kalman filter.

\begin{alg}[Recursive LS]
  \label{alg:recursive-ls}
  Initialize an estimate of the initial state $\hat{x}_0$ with $P_0
  = P_x = \Var{x}$. The recursion is as follows:
  Observe $\bar{z}_k$, then update
  \begin{align*}
    K_k &= P_{k-1} \mt{H}_k \minv{(H_k P_{k-1}\mt{H}_k + R_k)}, \\
    \hat{x}_k &= \hat{x}_{k-1} + K_k (\bar{z}_k - H_k \hat{x}_{k-1}), \\
    P_k &= (I - K_k H_k) P_{k-1} \mt{(I - K_k H_k)} + K_k R_k \mt{K}_k.
  \end{align*}
\end{alg}

An intuition for the structure of this estimator is given by the fact that if
the measurement coincides with the estimate then $\bar{z}_k - H_k \hat{x}_{k-1}
= 0$ and $\hat{x}_k = \hat{x}_{k-1}$.

\section{Kalman Filter}

The Kalman filter (KF) is a Bayesian estimator for linear time-varying (LTV)
systems with Gaussian process and measurement noise. The KF is particularly
exceptional because it has a closed form analytical solution.

\subsection{Problem Statement}

Consider a LTV system
\begin{align*}
  x(k) &= A(k-1) x(k-1) + u(k-1) + v(k-1), \\
  z(k) &= H(k) x(k) + w(k),
\end{align*}
where $x(k)$ is the state, $u(k)$ is a known control input, $v(k) \sim
\mathcal{N}(0, Q(k))$ is the process noise, $z(k)$ is the measurement and
$w(k) \sim \mathcal{N}(0, R(k))$ is the sensor noise. Further the initial
state $x(0) \sim \mathcal{N}(x_0, P_0)$ and $x(0), \{w(\cdot)\}$ and
$\{w(\cdot)\}$ are mutually independent.

\begin{remark}
  If $v(k)$ has nonzero mean, say $v(k) \sim \mathcal{N}(\alpha, Q(k))$ define
  $\bar{u} = u - \alpha$. Similarly if $w(k) \sim \mathcal{N}(\beta, R(k))$,
  redefine $\bar{z} = z - \beta$.
\end{remark}

\subsection{Bayesian Formulation} \label{sec:kalman:bayesian}

For the Bayesian interpretation of the KF we reformulate the problem using
auxiliary variables ``p'' for the prediction, and ``m'' for measurement:
\begin{align*}
  x_\mathrm{m}(0) &= x(0) \\
  x_\mathrm{p}(k) &= A(k-1) x_\mathrm{m}(k-1) + u(k-1) + v(k-1) \\
  z_\mathrm{m}(k) &= H(k) x_\mathrm{p}(k) + w(k)
\end{align*}
where $x_\mathrm{m}(k)$ is defined via its PDF
\[
  p_{x_\text{m}(k)}(\xi) = p_{x_\text{p}(k)|z_\text{m}(k)}(\xi | \bar{z}(k)),
  \quad\forall \xi.
\]

\begin{lemma} \label{lem:pdf-auxiliary}
  With the above formulation
  \begin{align*}
    p_{x_\mathrm{p}(k)}(\xi) &= p_{x(k)|z(1:k-1)}(\xi | \bar{z}(1:k-1)), \\
    p_{x_\mathrm{m}(k)}(\xi) &= p_{x(k)|z(1:k)}(\xi | \bar{z}(1:k)),
  \end{align*}
  for all $\xi$ and $k = 1,2,\ldots$. That is, $x_\mathrm{p}(k)$ is the RV
  $x(k)$ conditioned on $z(1:k-1)$ and $x_\mathrm{m}(k)$ is the RV $x(k)$
  conditioned on $z(1:k)$.
\end{lemma}
% \begin{proof}[Proof sketch]
% TODO: do the proof
% \end{proof}

Now, introducing the following notation for the mean and variance of the
prediction and measurement
\begin{align*}
  \hat{x}_\mathrm{p}(k) &= \E{x_\mathrm{p}(k)}, &
  P_\mathrm{p}(k) &= \Var{x_\mathrm{p}(k)}, \\
  \hat{x}_\mathrm{m}(k) &= \E{x_\mathrm{m}(k)}, &
  P_\mathrm{m}(k) &= \Var{x_\mathrm{m}(k)},
\end{align*}
we make use of the following fact:
\begin{lemma}
  For all $k$, $x_\mathrm{p}(k)$ and $x_\mathrm{m}(k)$ are GRVs.
\end{lemma}
% \begin{proof}[Proof sketch]
%   The proof is by induction. The claim is true by definition for
%   $x_\mathrm{m}(0)$. For $k \geq 1$ assume $x_\mathrm{m}(k-1)$ is a GRV to
%   show that this implies that $x_\mathrm{p}(k)$ and $x_\mathrm{m}(k)$ are
%   GRVs. This is accomplished by noting that $x_\mathrm{p}(k)$ and
%   $x_\mathrm{m}(k)$ are affine combinations of GRVs and making use of lemma
%   \ref{lem:affine-grv}. Further, $x_\mathrm{m}(k-1)$ and $v(k-1)$ are
%   independent, hence they are also jointly Gaussian by lemma
%   \ref{lem:independent-grvs-joint}.
% TODO: finish here
% \end{proof}

Hence, we can compute expressions for $\hat{x}_\mathrm{p}(k)$,
$P_\mathrm{p}(k)$, $\hat{x}_\mathrm{m}(k)$ and $P_\mathrm{m}(k)$, i.e. the
Kalman filter equations.

\begin{thm}[Kalman Filter Equations]
  The prior update or prediction step is
  \begin{align*}
    \hat{x}_\mathrm{p}(k) &= A(k-1) \hat{x}_\mathrm{m}(k-1) + u(k-1), \\
    P_\mathrm{p}(k) &= A(k-1) P_\mathrm{m}(k-1) \mt{A}(k-1) + Q(k-1),
  \end{align*}
  then, the a posteriori update or measurement step is
  \begin{align*}
    P_\mathrm{m}(k) &= \minv{(
        \minv{P}_\mathrm{p}(k) + \mt{H}(k) \minv{R}(k) H(k)
      )}, \\
    \hat{x}_\mathrm{m}(k) &= \hat{x}_\mathrm{p}(k)
      + P_\mathrm{m}(k) \mt{H}(k) \minv{R}(k)
        (\bar{z}(k) - H(k) \hat{x}_\mathrm{p}(k)).
  \end{align*}
\end{thm}

Therefore, the Kalman filter is the analytical solution to the Bayesian state
estimation problem for a linear system with Gaussian distributions.

\subsection{Alternate Formulation}

A more common formulation for the Kalman filter is as follows.

\begin{thm}[KF with Kalman Gain]
  Let
  \[
    K(k) = P_\mathrm{p}(k) \mt{H}(k) \minv{(
      H(k) P_\mathrm{p}(k) \mt{H}(k) + R(k)
    )}
  \]
  be the Kalman filter gain. Then, the a posteriori update can be computed
  with
  \begin{align*}
    \hat{x}_\mathrm{m}(k) &= \hat{x}_\mathrm{p}(k) + K(k)(
      \bar{z}(k) - H(k) \hat{x}_\mathrm{p}(k)
    ), \\
    P_\mathrm{m}(k) &= (I - K(k) H(k)) P_\mathrm{p}(k).
  \end{align*}
\end{thm}
% \begin{proof}[Proof sketch]
% TODO: do it
% \end{proof}

\begin{lemma}[Joseph form of the covariance update]
  In the a posteriori update of the KF with Kalman Gain $P_\mathrm{m}(k)$ can
  be computed with
  \begin{align*}
    P_\mathrm{m}(k) = (I - K(k) H(k)) 
      &P_\mathrm{p}(k) \mt{(I - K(k) H(k))} \\
      &+ K(k) R(k) \mt{K(k)}.
  \end{align*}
  This form is more computationally expensive, but less sensitive to numerical
  errors.
\end{lemma}


This is the same as the recursive least square algorithm
\ref{alg:recursive-ls}, therefore, the KF can also be applied to non-Gaussian
RVs. Then, the KF can be interpreted as a linear unbiased estimator that
minimizes the mean square error (MMSE). However, it the KF will no longer be
optimal in the Bayesian sense.

\begin{remark}
  If $A(k)$, $H(k)$, $Q(k)$, $R(k)$ and $P_0$ are known for all $k$,
  $P_\mathrm{p}(k)$, $P_\mathrm{m}(k)$ and $K(k)$ can all be precomputed
  offline.
\end{remark}

\begin{remark}
  The KF assumes positive definiteness for $P_0 \succ 0$, $Q(k) \succ 0$,
  $R(k) \succ 0$, however the KF also makes sense when they are positive
  semidefinite, as long the matrix inversions are well defined. That is, when
  some states are know exactly.
\end{remark}

\subsection{Detectability and Stabilizability}

\begin{defn}[Detectability]
  Consider the deterministic system
  \[
    x(k+1) = Ax(k), \quad
    z(k) = Hx(k),
  \]
  where $k = 0, 1, \ldots $ and $x(0) = x_0 \in \mathbb{R}^n$. The system is
  said to be detectable if
  \[
    \lim_{k\to\infty} z(k) = 0 \implies \lim_{k\to\infty} x(k) = 0,
  \]
  for any $x_0$.
\end{defn}

The above implies that the system is detectable iff $Hw \neq 0$ for any
eigenvector $w$ corresponding to an eigenvalue $|\lambda| \geq 1$ of the matrix
$A$. In other words, we need to be able to see unstable modes. This can be
expressed with the conditions:
\[
  \rank \begin{bmatrix}
    A - \lambda I \\
    H
  \end{bmatrix} = n, 
  \quad \forall \lambda \in \mathbb{C},
  \quad |\lambda| \geq 1,
\]
i.e. is full rank (PBH Test); Or, the eigenvalues of $A - LH$ or $(I - LH)A$
can be placed within the unit circle by a suitable choice of
$L\in\mathbb{R}^{n\times m}$

\begin{defn}[Stabilizability]
  Consider the deterministic system
  \[
    x(k+1) = Ax(k) + Bu(k), \quad
    z(k) = Hx(k),
  \]
  where $k = 0, 1, \ldots $ and $x(0) = x_0$, $A \in \mathbb{R}^{n\times n}$,
  $B \in\mathbb{R}^{n\times m}$. The system is said to be stabilizable if
  \[
    \exists u(0:k-1) \text{ such that } \lim_{k\to\infty} x(k) = 0
  \]
  for any $x_0$.
\end{defn}
Equivalently, if $\begin{bmatrix} A - \lambda I & B \end{bmatrix}$ is full
rank for all $\lambda \in \mathbb{C}$ with $|\lambda| \geq 1$ (PBH Test); Or
if the eigenvalues of $A - BK$ or $(I - BK)A$ can be placed within the unit
circle by choosing $K\in \mathbb{R}^{m\times n}$. Stabilizability is the dual
of detectability, i.e. $(A, B)$ is stabilizable iff $(\mt{A}, \mt{B})$ is
detectable.

% TODO: remark that stabilizability and detectability are weaker statements of
% controllability and observaility

\subsection{The Steady-State KF}

If the variance $P_\mathrm{p}(k)$ converges, so does $P_\mathrm{m}(k)$ and the
KF gain: $\lim_{k\to\infty} K(k) = K_\infty$. The time invariance of
$K_\infty$ makes the implementation easier.

\begin{defn}[Steady-State KF Gain, DARE]
  Assuming $P_\mathrm{p}(k)$ converges to $P_\infty$, then
  \begin{align*}
    P_\mathrm{p}(k+1) &= A P_\mathrm{p}(k) \mt{A} + Q \\
      &- A P_\mathrm{p}(k)
      \mt{H} \minv{( H P_\mathrm{p}(k) \mt{H} + R)} H P_\mathrm{p}(k) \mt{A}
  \end{align*}
  (obtained by combining the KF equations) becomes the \emph{discrete
  algebraic Riccati equation} (DARE)
  \[
    P_\infty = A P_\infty \mt{A} + Q - A P_\infty \mt{H}
      \minv{(H P_\infty \mt{H} + R)} H P_\infty \mt{A},
  \]
  and $K_\infty = P_\infty \mt{H}\minv{(H P_\infty \mt{H} + R)}$.
\end{defn}

% TODO: remarks on convergence of P_\infty to the trivial (useless) solution

\begin{thm}
  Assume $R \succ 0$, $Q \succeq 0$, and let $G$ be any matrix such that $Q =
  G\mt{G}$. Then the following statements are equivalent
  \begin{itemize}
    \item $(A, H)$ is detectable and $(A, G)$ is stabilizable.
    \item The DARE has a unique solution $P_\infty \succeq 0$, $(I - K_\infty
      H)A$ is stable and
      \[
        \lim_{k\to\infty} P_\mathrm{p}(k) = P_\infty
        \text{ for any } P_\mathrm{p}(1) \succeq 0
      \]
      and hence any $P_\mathrm{m}(0) = P_0 \succeq 0$.
  \end{itemize}
\end{thm}

\begin{remark}
  $(A,H)$ detectable means that all unstable modes can be observed, and
  $(A,G)$ stabilizable means that noise excites unstable modes (if $Q \succ 0$, then
  this always holds).
\end{remark}

\section{Extended Kalman Filter (EKF)}

\subsection{Problem Statement}

Consider the nonlinear discrete-time system
\[
  x(k) = q_{k-1}(x(k-1), v(k-1)), 
  \quad z(k) = h_k(x(k), w(k)),
\]
where
\begin{align*}
  \E{x(0)} &= x_0, & \Var{x(0)} &= P_0, \\
  \E{v(k-1)} &= 0, & \Var{v(k-1)} &= Q(k-1), \\
  \E{w(k)} &= 0, & \Var{w(k)} &= R(k).
\end{align*}
Moreover, $x(0)$, $\{v(\cdot)\}$, $\{w(\cdot)\}$ are mutually independent,
$q_{k-1}$ is continuously differentiable wrt $x(k-1)$ and $v(k-1)$, and
$h_{k}$ is continuously differentiable wrt $x(k)$ and $w(k)$. That is, a
system that is mildly nonlinear. Any known input to the system is implicitly
absorbed in $q_{k-1}$.

\subsection{The EKF Equations}

The EKF works by linearizing the nonlinear system at the current state
estimate and then apply the KF equations.

% TODO: initialization of the EKF

\begin{thm}[EKF process update equations]
  Linearizing $q_{k-1}(x(k-1), v(k-1))$ about $\hat{x}_\mathrm{m}(k-1)$ and
  $\E{v(k-1)} = 0$ yields
  \[
    x(k) \approx A(k-1) x(k-1) + L(k-1) v(k-1) + \xi(k-1),
  \]
  where
  \begin{align*}
    A(k-1) &= \partial_x q_{k-1}(\hat{x}_\mathrm{m}(k-1), 0), \\
    L(k-1) &= \partial_v q_{k-1}(\hat{x}_\mathrm{m}(k-1), 0), \\
    \xi(k-1) &= q_{k-1}(\hat{x}_\mathrm{m}(k-1),0) -
    A(k-1)\hat{x}_\mathrm{m}(k-1).
  \end{align*}
  The noise $L(k-1)v(k-1)$ is zero-mean with variance
  $L(k-1)Q(k-1)\mt{L}(k-1)$. The update equations are
  \begin{align*}
    \hat{x}_\mathrm{p}(k) &= q_{k-1}(\hat{x}_\mathrm{m}(k-1), 0) \\
    P_\mathrm{p}(k) &= A(k-1) P_\mathrm{m}(k-1) \mt{A}(k-1) \\
      &\qquad + L(k-1) Q(k-1) \mt{L}(k-1).
  \end{align*}
\end{thm}

Intuition: Predict the mean state estimate forward using the nonlinear process
model and update the variance according to the linearized equations.

\begin{thm}[EKF measurement update equations]
  Linearizing $h_k(x(k), w(k))$ about $\hat{x}_\mathrm{p}(k)$ and $\E{w(k)} =
  0$ yields
  \[
    z(k) \approx H(k) x(k) + M(k) w(k) + \zeta(k),
  \]
  where
  \begin{align*}
    H(k) &= \partial_x h_{k}(\hat{x}_\mathrm{p}(k), 0), \\
    M(k) &= \partial_w h_{k}(\hat{x}_\mathrm{p}(k), 0), \\
    \zeta(k) &= h_k(\hat{x}_\mathrm{p}(k), 0) - H(k) \hat{x}_\mathrm{p}(k).
  \end{align*}
  The term $\zeta(k)$ known and can be removed by defining the auxiliary
  measurement $z(k) - \zeta(k)$. The noise $M(k)w(k)$ is zero-mean with
  variance $M(k)R(k)\mt{M}(k)$, and the update equations are
  \begin{align*}
    K(k) &= P_\mathrm{p}(k) \mt{H}(k) (
        H(k) P_\mathrm{p}(k) \mt{H}(k) \\
        &\qquad\qquad\qquad + M(k) R(k) \mt{M}(k) \minv{)}, \\
    \hat{x}_\mathrm{m}(k) &= \hat{x}_\mathrm{p}(k) + K(k) (
        \bar{z}(k) - h_k(\hat{x}_\mathrm{p}(k), 0)), \\
    P_\mathrm{m}(k) &= (I - K(k)H(k)) P_\mathrm{p}(k).
  \end{align*}
\end{thm}

Intuition: correct for the mismatch between the actual measurement
$\bar{z}(k)$ and its nonlinear prediction $h_k(\hat{x}_\mathrm{p}(k), 0)$,
and correct the variance according to the linearized equations.

\begin{remark}
  In this case the Kalman gain cannot be computed offline even if the noise
  distributions are known for all $k$, hence the EKF is more computationally
  expensive.
\end{remark}

The EKF variables $\hat{x}_\mathrm{p}(k)$, $\hat{x}_\mathrm{m}(k)$,
$P_\mathrm{p}(k)$ and $P_\mathrm{m}$ are only approximations! The EKF would be
exact if $q_{k-1}$ and $\E{\cdot}$ commuted:
\[
  \E{q_{k-1}(x, v)} = q_{k-1}(\E{x}, \E{v})
\]
(the same is also for $h_k$), which is not the case for general nonlinear
$q_{k-1}$, but true for linear $q_{k-1}$.

Therefore, the EKF does not have general convergence guarantees, but it works
well for mildly nonlinear systems with unimodal noise distributions.

\subsection{Hybrid EKF}

In practice the process dynamics are usually continuous in time, and
measurement taken a discrete time steps. That is
\[
  \dot{x}(t) = q(x(t), v(t), t),
  \quad z[k] = h_k(x[k], w[k]),
\]
with $\E{w[k]} = 0$, $\Var{w[k]} = R$ (assumed constant for simplicity). We
use the notation $x[k] = x(kT)$ with $T$ being a constant sampling time.

\begin{remark}
  One could discretize the dynamics and work with the EKF above. However, if
  the process is ``fast'' (needs very small $T$), working with a lot of
  samples may end up being more expensive than the hybrid EKF which works with
  the continuous-time dynamics.
\end{remark}

\begin{defn}[White Noise]
  A discrete time signal $v_\mathrm{d}[k]$ is said to be white noise if
  $\E{v_\mathrm{d}[k]} = 0$ and $\E{v_\mathrm{d}[k] \mt{v_\mathrm{d}}[k+n]} =
  Q\delta_\mathrm{d}[n]$, where $n$ is an integer and $\delta_\mathrm{d}[n]$
  is the Kroneker delta, i.e $\delta_\mathrm{d}[0] = 1$ and
  $\delta_\mathrm{d}[n] = 0$ when $n \neq 0$.

  Similarly a continuous time signal $v(t)$ is white noise if $\E{v(t)} = 0$
  and $\E{v(t) \mt{v(t)}} = Q_c \delta(\tau)$ where $\delta(\tau)$ is the
  Dirac delta, which may be defined as
  \[
    \delta(\tau) = \lim_{\epsilon \to 0} \begin{cases}
      1/(2\epsilon) & -\epsilon < \tau < \epsilon \\
      0 & \text{otherwise}
    \end{cases}.
  \]
\end{defn}

\begin{remark}
  True continuous white noise cannot exist because it would have infinite
  power (has constant power spectral density), but it is nonetheless a useful
  approximation.
\end{remark}

\begin{thm}
  The Dirac pulse has the property that
  \[
    \int_a^b \xi(\tau) \delta(\tau) ~d\tau = \xi(0),
  \]
  for all $a < 0$ and $b > 0$ and any real valued function $\xi(t)$ that is
  continuous at 0.
\end{thm}

\begin{thm}[Hybrid EKF process update]
  Solve in the interval $(k-1)T \leq t \leq kT$ the ODE
  \[
    \dot{\hat{x}}(t) = q(\hat{x}(t), 0, t), 
    \quad \hat{x}((k-1)T) = \hat{x}_\mathrm{m}[k-1]
  \]
  and set $\hat{x}_\mathrm{p}[k] = \hat{x}(kT)$. Then solve in the same
  interval the matrix ODE
  \[
    \dot{P}(t) = A(t)P(t) + P(t) \mt{A}(t) + L(t) Q_c \mt{L}(t),
  \]
  where $A(t) = \partial_x q(\hat{x}(t), 0, t)$ and $L(t) = \partial_v
  q(\hat{x}, 0, t)$ with $P((k-1)T) = P_\mathrm{m}[k-1]$. Then set
  $P_\mathrm{p}[k] = P(kT)$.
\end{thm}
% not enough space to put the proof :(
% \begin{proof}[Proof]
%   Consider only $0 \leq t \leq T$ and generalize later for other $k$. To obtain
%   the mean update we take the expectation of the dynamics $\E{\dot{x}(t)} =
%   \E{q(x(t), v(t), t)}$. Then the time-derivative and $\E{\cdot}$ commute, and
%   we assume that $\E{q(\cdot)} \approx q(\E{\cdot})$ to get the ODE for
%   $\hat{x}(t)$.
% 
%   For the variance update linearize the system with $A(t) = \partial_x
%   q(\hat{x}(t), 0, t)$, $L(t) = \partial_v q(\hat{x}(t), 0, t)$ and let
%   $\tilde{x} = x(t) - \hat{x}(t)$, assume $\tilde{x}$ and $v(t)$ are small
%   (may be a bad assumption, especially if $v(t)$ is unbounded). Then
%   $\dot{\tilde{x}} \approx A(t) \tilde{x}(t) + L(t)\tilde{x}$, and
%   \begin{gather*}
%     \tilde{x}(t + \tau) \approx \tilde{x}(t) + \int_t^{t + \tau}
%       A(\xi)\tilde{x}(\xi) + L(\xi) v(\xi) ~ d\xi \\
%       \approx \tilde{x}(t) + \tau A(t) \tilde{x}(t) + L(t) \int_t^{t + \tau}
%         v(\xi) ~ d\xi + \mathcal{O}(\tau^2),
%   \end{gather*}
%   by linearizing around $\tau = 0$. The integral of $v(\xi)$ cannot be
%   approximated since $v(\xi) = Q_c\delta(\xi)$ is not continuous. Now, define
%   $P(t) = \Var{x(t)} \approx \E{\tilde{x}(t) \mt{\tilde{x}}(t)}$ similar as in
%   the mean, then
%   \begin{align*}
%     &P(t + \tau) \approx P(t) + \tau A(t) P(t) + \tau P(t) \mt{A}(t) \\
%       &\qquad + L(t) \iint_{[t, t + \tau]^2} \E{v(\xi)\mt{v}(\eta)} d\xi d\eta ~\mt{L}(t)
%       + \mathcal{O}(\tau^2) \\
%     &= P(t) + \tau A(t) P(t) + \tau P(t) \mt{A}(t)
%       + \tau L(t) Q_c \mt{L}(t) + \mathcal{O}(\tau^2),
%   \end{align*}
%   where in the second step we used the fact that the integrand equals $Q_c
%   \delta(\xi - \eta)$. Reordering the equation to get $(P(t + \tau) - P(t)) /
%   \tau$ on the RHS and letting $\tau \to 0$ yields the variance update ODE.
% \end{proof}

The measurement equations are the same as the discrete-time EKF.

\begin{thm}[Hybrid EKF measurement update]
  Let
  \[
    H[k] = \partial_x h_k(\hat{x}_\mathrm{p}[k], 0),
    \quad
    M[k] = \partial_w h_k(\hat{x}_\mathrm{p}[k], 0).
  \]
  Then the update equations are
  \begin{align*}
    K[k] &= P_\mathrm{p} \mt{H}[k]\minv{(
      H[k] P_\mathrm{p}[k] \mt{H}[k] + M[k] R \mt{M}[k])}, \\
    \hat{x}_\mathrm{m}[k] &= \hat{x}_\mathrm{p}[k]
      + K[k](\bar{z} - h_k(\hat{x}_\mathrm{p}[k], 0)), \\
    P_\mathrm{m}[k] &= (I - K[k] H[k]) P_\mathrm{p}[k].
  \end{align*}
\end{thm}

\begin{remark}
  Solving the matrix ODE is usually done with numerical ODE solvers such as
  Runge-Kutta (\textsc{matlab} e.g. \texttt{ode45}), and the accuracy largely
  depends on the order of the solver. Numerical accuracy is often at the cost
  of increased computation.
\end{remark}

\section{Particle Filter (PF)}

The basic idea of the particle filter is to approximate the Bayesian state
estimator for nonlinear systems and general (non Gaussian) noise
distributions, by representing the state PDF by a large number of samples
called \emph{particles}. The overview of the particle filter is as follows:
\begin{itemize}
  \item the particles are propagate through the process model,
  \item the particles are then weighted according to the measurement
    likelihood,
  \item a resampling generates a new set of particles.
\end{itemize}

\subsection{Problem Statement}

Consider the nonlinear discrete-time system
\[
  x(k) = q_{k-1}(x(k-1), v(k-1)),
  \quad
  z(k) = h_k(x(k), w(k)),
\]
where $x(0)$, $\{v(\cdot)\}$ and $\{w(\cdot)\}$ are mutually independent and
can be CRVs or DRVs with known PDF (no assumption on the shape of the PDF).
Any known input is implicitly absorbed in $q_{k-1}(\cdot)$.

\subsection{Monte Carlo (MC) Sampling}

MC sampling is a basic technique o fusing a large number of samples called
particles to approximate the PDF of a RV.

\paragraph{MC approximant of a DRV}

Let $y \in \mathcal{Y} = \{1,2,\ldots,\bar{Y}\}$ be a DRV with PDF $p_y$.
Then let $\{y^1, y^2, \ldots, y^N\}$ i.i.d with PDF $p_y$ be DRVs model
$N$ random samples of $y$, and define
\[
  s_i^n = \delta(i - y^n) = \begin{cases} 1 & \text{if } y^n = i \\
    0 & \text{otherwise} \end{cases},
\]
where $i = 1,\ldots,\bar{Y}$ and $n = 1, \ldots N$ (there are $N\times
\bar{Y}$ $s_i^n$'s). By the law of the unconscious statistician
\[
  \E[y^n]{s^n_i} =
    \sum_{\bar{y}^n = 1}^{\bar{Y}} \delta(i - \bar{y}^n) p_y(\bar{y}^n)
    = p_y(i).
\]
Conversely, let the DRV $s_i$ denote the average of $s_i^n$ over $n$: $s_i =
\frac{1}{N} \sum_{n=1}^N s_i^n$. By the law of large numbers
(LLN) $\lim_{N\to\infty} s_i = \E[y^n]{s_i^n} = p_y(i)$. By denoting the values that
the random variables $s_i^n$ take by $\bar{s}_i^n$, the can approximately
write
\[
  p_y(i) \approx \frac{1}{N} \sum_{n=1}^N \bar{s}_i^n.
\]

\paragraph{MC approximant of a CRV}

Let $y$ be a CRV with PDF $p_y$. First we bin the CRV by letting $\Delta y$ be
a fixed bin size, and let $y^n$, $n=1,2,\ldots,N$ be i.i.d with PDF $p_y$.
Like in the DRV define
\[
  s^n_a = \int_a^{a+\Delta y} \delta(\xi - y^n) ~d\xi =
  \begin{cases}
    1 & \text{if } y^n \in [a, a+\Delta y) \\
    0 & \text{otherwise}
  \end{cases}.
\]
with $a$ indexing the bins. Again, by the law of the unconscious statistician
\begin{align*}
  \E[y^n]{s^n_a} &= \int_\mathbb{R} \left[
      \int_a^{a+\Delta y} \delta(\xi - \bar{y}^n) ~d\xi
    \right] p_y(\bar{y}^n) ~d\bar{y}^n \\
  &= \int_a^{a+\Delta y} p_y(\bar{y}^n) ~d\bar{y}^n
    = \Pr{a \leq y < a + \Delta y}.
\end{align*}
Hence $\lim_{N\to\infty} \frac{1}{N} \sum_{n=1}^N s^n_a = \E[y^n]{s_a^n} =
\Pr{y \in [a,a+\Delta y)}$ by the LLN, since
\begin{align*}
  \frac{1}{N} \sum_{n=1}^N s_a^n
    &= \frac{1}{N} \sum_{n=1}^N \int_a^{a + \Delta y}
      \delta(\xi - y^n) ~d\xi \\
    &= \int_a^{a + \Delta y} \frac{1}{N} \sum_{n=1}^N
      \delta(\xi - y^n) ~d\xi \to \int_a^{a+\Delta y} p_y(\bar{y}) ~d\bar{y}.
\end{align*}
Thus for a smooth and bounded $p_y$ and small $\Delta y$ we approximate
\[
  p_y(\xi) \approx \frac{1}{N} \sum_{n=1}^N \delta(\xi - \bar{y}^n), 
  \quad \forall \xi,
\]
where we understand it in the sense that if you integrate both you get similar
numbers.

\paragraph{Change of variables for MC approximant}

Consider $x = g(y)$, with $x \in \mathcal{X} = g(\mathcal{Y})$. Let $x^n =
g(y^n)$, $j \in \mathcal{X}$, and $r^n_j = \delta(j - x^n)$ (similar to
$s_i^n$), then
\[
  p_x(j) \approx \frac{1}{N} \sum_{n=1}^N \delta(j - g(\bar{y}^n)),
  \quad j \in g(\mathcal{Y}),
\]
i.e. we can approximate $p_x$ by using samples from $p_y$. This also holds for
joint RVs
\[
  p_x(\xi) \approx \frac{1}{N} \sum_{n=1}^N \delta(\xi - \bar{x}^n), 
  \quad \forall \xi,
\]
where $\xi$ and $\bar{x}^n$ may be vectors. Moreover, $\mathcal{X}$ and
$\mathcal{Y}$ may also be infinite.

\subsection{The Particle Filter}

We take the general Bayesian estimator of \S\ref{sec:bayesian-tracking} and
similar to \S\ref{sec:kalman:bayesian} we define the auxiliary variables
$x_\mathrm{p}(k), x_\mathrm{m}(k), z_\mathrm{m}(k)$, however, unlike in the KF
we make no assumption on the shape of the PDF nor assume a linear $q_{k-1}$.
Hence
\begin{align*}
  x_\mathrm{p}(k) &= q_{k-1}(x_\mathrm{m}(k-1), v(k-1)) \\
  z_\mathrm{m}(k) &= h_k(x_\mathrm{p}(k), w(k)) \\
  p_{x_\mathrm{m}}(k) &= p_{x_\mathrm{p} | z_\mathrm{m}(k)}(\xi | \bar{z}(k)),
  \quad\forall \xi.
\end{align*}
with $x_\mathrm{m}(0) = x(0)$, and with lemma \ref{lem:pdf-auxiliary}:
\begin{align*}
  p_{x_\mathrm{p}(k)}(\xi) &= p_{x(k)|z(1:k-1)}(\xi | \bar{z}(1:k-1)), \\
  p_{x_\mathrm{m}(k)}(\xi) &= p_{x(k)|z(1:k)}(\xi | \bar{z}(1:k)).
\end{align*}

\paragraph{Prior Update} Given the PDF $p_{x_\mathrm{m}(k-1)}$ we construct
$p_{x_\mathrm{p}(k)}$ by approximating both with MC sampling. Let
\[
  p_{x_\mathrm{m}(k-1)}(\xi) \approx
    \frac{1}{N} \sum_{n=1}^N \delta(\xi - \bar{x}^n_{\mathrm{m}}(k-1)),
    \quad\forall\xi
\]
where $\{\bar{x}^n_{\mathrm{m}}(k-1)\}$ are $N$ particles to approximate
$x_\mathrm{m}(k-1)$. Then
\begin{gather*}
  p_{x_\mathrm{p}(k)}(\xi) \approx
    \frac{1}{N} \sum_{n=1}^N \delta(\xi - \bar{x}^n_{\mathrm{p}}(k)),
    \quad\forall\xi \\
  \text{where} \quad
  \bar{x}^n_{\mathrm{p}}(k)
  = q_{k-1}(\bar{x}^n_{\mathrm{m}}(k-1), \bar{v}^n(k-1)),
\end{gather*}
and $\{\bar{v}^n(k-1)\}$ are MC samples of $p_{v(k-1)}$. In words: we
``simply'' propagate the particles through the dynamics.

\paragraph{Measurement Update (and Resampling)}

Given the PDF $p_{x_\mathrm{p}(k)}$ of $x_\mathrm{p}(k) \in \mathcal{X}$ and a
measurement $\bar{z}(k)$ we approximately construct $p_{x_\mathrm{m}(k)}$
using MC sampling. By Bayes' rule (proposition \ref{pro:measurement-update} in
\S\ref{sec:bayesian-tracking:recursive-estimator}):
\[
  p_{x_\mathrm{m}(k)}(\xi) = \frac{
    p_{z_\mathrm{m}(k) | x_\mathrm{p}(k)} (\bar{z}(k) | \xi)
    ~
    p_{x_\mathrm{p}(k)}(\xi)
  }{
    \sum_{\zeta\in\mathcal{X}}
      p_{z_\mathrm{m}(k) | x_\mathrm{p}(k)} (\bar{z}(k) | \zeta)
      ~
      p_{x_\mathrm{p}(k)}(\zeta)
  },
  \quad\forall \xi.
\]
Substituting the MC approximation\footnote{and making use of the fact that
$f(\xi) \delta(\xi) = f(0) \delta(\xi)$} for $p_{x_\mathrm{p}(k)}$
\[
  p_{x_\mathrm{m}(k)}(\xi) \approx
    \sum_{n=1}^N \beta_n \delta(\xi - \bar{x}_\mathrm{p}^n(k))
\]
where $\sum_{n=1}^N \beta_n = 1$, and
\begin{align*}
  \beta_n &= \alpha ~ p_{z_\mathrm{m}(k) | x_\mathrm{p}(k)}
    (\bar{z} | \bar{x}_\mathrm{p}^n(k)), \\
  \alpha &= \left( \sum_{n=1}^N
    p_{z_\mathrm{m}(k) | x_\mathrm{p}(k)}
      (\bar{z}(k) | \bar{x}_\mathrm{p}^n(k))
  \right)^{-1}.
\end{align*}
In words: at points of high prior there are many particles, in the posterior
they are scaled by the measurement likelihood.

To complete the measurement update we need to resample the particles. This is
algorithm \ref{alg:sample-drv} of
\S\ref{sec:probability-review:sampling-distributions}. Repeat $N$ times:
\begin{itemize}
  \item Select a random number $r \sim \mathcal{U}(0,1)$,
  \item Pick particle $\bar{n}$ such that
    \[
      \sum_{n=1}^{\bar{n}-1} \beta_n < r
      \quad\text{and}\quad
      \sum_{n=1}^{\bar{n}} \beta_n \geq r.
    \]
\end{itemize}
The result are $N$ \emph{new} particles $\bar{x}_\mathrm{m}^n(k)$ from a
subset of the old particles that have all equal weight.

\subsection{Sample Impoverishment}

A possible problem of the PF is that all particles may converge to the same
one and become a bad representation of the PDF. This is because we have a
finite number of samples $N$, and is called \emph{sample impoverishment}. The
simplest solution to prevent this is \emph{roughening}.

After the resampling perturb the particles with
\[
  \bar{x}_\mathrm{m}^n(k) \leftarrow \bar{x}_\mathrm{m}^n(k) + \Delta x^n(k),
\]
where $\Delta x^n(k)$ is drawn from a zero-mean, finite-variance distribution.
To choose the variance of said distribution a simple way is to let
\[
  \sigma_i = K E_i N^{-1/d},
\]
where $K \ll 1$ is a tuning parameter, $d$ is the dimension of the state
space, $E_i = \max_{n_1, n_2} | x_{\mathrm{m},i}^{n_1} -
x_{\mathrm{m},i}^{n_1} |$ is the maximum inter-sample variability and
$N^{-1/d}$ is related to the spacing between nodes of a uniform grid.

\end{document}
